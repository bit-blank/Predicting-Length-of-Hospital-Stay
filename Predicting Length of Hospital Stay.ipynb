{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a75a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3b12af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (2.0.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (5.17.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (9.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\prakhar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\PRAKHAR\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a2d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\PRAKHAR\\Desktop/Healthcare_Investments_and_Hospital_Stay (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7deef76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Time</th>\n",
       "      <th>Hospital_Stay</th>\n",
       "      <th>MRI_Units</th>\n",
       "      <th>CT_Scanners</th>\n",
       "      <th>Hospital_Beds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1992</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1.43</td>\n",
       "      <td>16.71</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1994</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.36</td>\n",
       "      <td>18.48</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1995</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>20.55</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1996</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.96</td>\n",
       "      <td>21.95</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUS</td>\n",
       "      <td>1997</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.53</td>\n",
       "      <td>23.34</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>LTU</td>\n",
       "      <td>2014</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.57</td>\n",
       "      <td>22.17</td>\n",
       "      <td>10.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>LTU</td>\n",
       "      <td>2015</td>\n",
       "      <td>6.6</td>\n",
       "      <td>11.02</td>\n",
       "      <td>21.00</td>\n",
       "      <td>11.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>LTU</td>\n",
       "      <td>2016</td>\n",
       "      <td>6.6</td>\n",
       "      <td>12.20</td>\n",
       "      <td>23.01</td>\n",
       "      <td>12.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>LTU</td>\n",
       "      <td>2017</td>\n",
       "      <td>6.5</td>\n",
       "      <td>12.37</td>\n",
       "      <td>23.33</td>\n",
       "      <td>12.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>LTU</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.5</td>\n",
       "      <td>12.49</td>\n",
       "      <td>24.27</td>\n",
       "      <td>12.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Location  Time  Hospital_Stay  MRI_Units  CT_Scanners  Hospital_Beds\n",
       "0        AUS  1992            6.6       1.43        16.71           1.43\n",
       "1        AUS  1994            6.4       2.36        18.48           2.36\n",
       "2        AUS  1995            6.5       2.89        20.55           2.89\n",
       "3        AUS  1996            6.4       2.96        21.95           2.96\n",
       "4        AUS  1997            6.2       3.53        23.34           3.53\n",
       "..       ...   ...            ...        ...          ...            ...\n",
       "513      LTU  2014            6.8      10.57        22.17          10.57\n",
       "514      LTU  2015            6.6      11.02        21.00          11.02\n",
       "515      LTU  2016            6.6      12.20        23.01          12.20\n",
       "516      LTU  2017            6.5      12.37        23.33          12.37\n",
       "517      LTU  2018            6.5      12.49        24.27          12.49\n",
       "\n",
       "[518 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e689eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 518 entries, 0 to 517\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Location       518 non-null    object \n",
      " 1   Time           518 non-null    int64  \n",
      " 2   Hospital_Stay  518 non-null    float64\n",
      " 3   MRI_Units      518 non-null    float64\n",
      " 4   CT_Scanners    518 non-null    float64\n",
      " 5   Hospital_Beds  518 non-null    float64\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 24.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4095f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encode(df, column):\n",
    "    df = df.copy()\n",
    "    dummies = pd.get_dummies(df[column])\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop(column, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617b1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # One-hot encode Location column\n",
    "    df = onehot_encode(df, column='Location')\n",
    "    \n",
    "    # Split df into X and y\n",
    "    y = df['Hospital_Stay'].copy()\n",
    "    X = df.drop('Hospital_Stay', axis=1).copy()\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "    \n",
    "    # Scale X with a standard scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a69cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_inputs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e5a709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>MRI_Units</th>\n",
       "      <th>CT_Scanners</th>\n",
       "      <th>Hospital_Beds</th>\n",
       "      <th>AUS</th>\n",
       "      <th>AUT</th>\n",
       "      <th>BEL</th>\n",
       "      <th>CAN</th>\n",
       "      <th>CZE</th>\n",
       "      <th>DEU</th>\n",
       "      <th>...</th>\n",
       "      <th>LVA</th>\n",
       "      <th>NLD</th>\n",
       "      <th>NZL</th>\n",
       "      <th>POL</th>\n",
       "      <th>PRT</th>\n",
       "      <th>RUS</th>\n",
       "      <th>SVK</th>\n",
       "      <th>SVN</th>\n",
       "      <th>TUR</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.303643</td>\n",
       "      <td>0.502340</td>\n",
       "      <td>-0.349986</td>\n",
       "      <td>0.502340</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.738679</td>\n",
       "      <td>-0.697320</td>\n",
       "      <td>-0.873325</td>\n",
       "      <td>-0.697320</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131392</td>\n",
       "      <td>-0.562147</td>\n",
       "      <td>-0.392384</td>\n",
       "      <td>-0.562147</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>4.809712</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276404</td>\n",
       "      <td>-0.018076</td>\n",
       "      <td>-0.295665</td>\n",
       "      <td>-0.018076</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>6.262765</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.001462</td>\n",
       "      <td>1.174825</td>\n",
       "      <td>1.272365</td>\n",
       "      <td>1.174825</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1.146474</td>\n",
       "      <td>-0.248996</td>\n",
       "      <td>-0.302952</td>\n",
       "      <td>-0.248996</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>4.809712</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.276404</td>\n",
       "      <td>-0.678170</td>\n",
       "      <td>-0.378472</td>\n",
       "      <td>-0.678170</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>5.648813</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>-0.013620</td>\n",
       "      <td>-0.589181</td>\n",
       "      <td>-0.850140</td>\n",
       "      <td>-0.589181</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>-0.013620</td>\n",
       "      <td>-0.317709</td>\n",
       "      <td>-0.623580</td>\n",
       "      <td>-0.317709</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>5.181327</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.421415</td>\n",
       "      <td>-0.539618</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>-0.539618</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.215041</td>\n",
       "      <td>-0.207913</td>\n",
       "      <td>-0.16855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.159674</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.052632</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.177028</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.193001</td>\n",
       "      <td>-0.140422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time  MRI_Units  CT_Scanners  Hospital_Beds       AUS       AUT   \n",
       "0   -0.303643   0.502340    -0.349986       0.502340 -0.207913 -0.207913  \\\n",
       "1   -0.738679  -0.697320    -0.873325      -0.697320 -0.207913 -0.207913   \n",
       "2    0.131392  -0.562147    -0.392384      -0.562147 -0.207913 -0.207913   \n",
       "3    0.276404  -0.018076    -0.295665      -0.018076 -0.207913 -0.207913   \n",
       "4    1.001462   1.174825     1.272365       1.174825 -0.207913 -0.207913   \n",
       "..        ...        ...          ...            ...       ...       ...   \n",
       "357  1.146474  -0.248996    -0.302952      -0.248996 -0.207913 -0.207913   \n",
       "358  0.276404  -0.678170    -0.378472      -0.678170 -0.207913 -0.207913   \n",
       "359 -0.013620  -0.589181    -0.850140      -0.589181 -0.207913 -0.207913   \n",
       "360 -0.013620  -0.317709    -0.623580      -0.317709 -0.207913 -0.207913   \n",
       "361  0.421415  -0.539618     0.003102      -0.539618 -0.207913 -0.207913   \n",
       "\n",
       "          BEL       CAN       CZE      DEU  ...       LVA       NLD       NZL   \n",
       "0   -0.177028 -0.215041 -0.207913 -0.16855  ... -0.193001 -0.177028 -0.159674  \\\n",
       "1   -0.177028 -0.215041 -0.207913 -0.16855  ... -0.193001 -0.177028 -0.159674   \n",
       "2   -0.177028 -0.215041  4.809712 -0.16855  ... -0.193001 -0.177028 -0.159674   \n",
       "3   -0.177028 -0.215041 -0.207913 -0.16855  ... -0.193001 -0.177028  6.262765   \n",
       "4   -0.177028 -0.215041 -0.207913 -0.16855  ... -0.193001 -0.177028 -0.159674   \n",
       "..        ...       ...       ...      ...  ...       ...       ...       ...   \n",
       "357 -0.177028 -0.215041  4.809712 -0.16855  ... -0.193001 -0.177028 -0.159674   \n",
       "358 -0.177028 -0.215041 -0.207913 -0.16855  ... -0.193001 -0.177028 -0.159674   \n",
       "359 -0.177028 -0.215041 -0.207913 -0.16855  ... -0.193001 -0.177028 -0.159674   \n",
       "360 -0.177028 -0.215041 -0.207913 -0.16855  ... -0.193001 -0.177028 -0.159674   \n",
       "361 -0.177028 -0.215041 -0.207913 -0.16855  ... -0.193001 -0.177028 -0.159674   \n",
       "\n",
       "          POL       PRT       RUS       SVK       SVN       TUR       USA  \n",
       "0   -0.177028 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "1   -0.177028 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "2   -0.177028 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "3   -0.177028 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "4   -0.177028 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "357 -0.177028 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "358  5.648813 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "359 -0.177028 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "360 -0.177028 -0.052632 -0.193001 -0.177028 -0.140422  5.181327 -0.140422  \n",
       "361 -0.177028 -0.052632 -0.193001 -0.177028 -0.140422 -0.193001 -0.140422  \n",
       "\n",
       "[362 rows x 36 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4230a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121    7.2\n",
       "378    7.3\n",
       "91     6.7\n",
       "310    6.1\n",
       "479    5.9\n",
       "      ... \n",
       "98     5.9\n",
       "322    7.3\n",
       "382    6.3\n",
       "365    4.1\n",
       "510    7.0\n",
       "Name: Hospital_Stay, Length: 362, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02494e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression trained.\n",
      "                   K-Nearest Neighbors trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PRAKHAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PRAKHAR\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Neural Network trained.\n",
      "Support Vector Machine (Linear Kernel) trained.\n",
      "   Support Vector Machine (RBF Kernel) trained.\n",
      "                         Decision Tree trained.\n",
      "                         Random Forest trained.\n",
      "                     Gradient Boosting trained.\n",
      "                               XGBoost trained.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 396\n",
      "[LightGBM] [Info] Number of data points in the train set: 362, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 7.151934\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "                              LightGBM trained.\n",
      "                              CatBoost trained.\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"                     Linear Regression\": LinearRegression(),\n",
    "    \"                   K-Nearest Neighbors\": KNeighborsRegressor(),\n",
    "    \"                        Neural Network\": MLPRegressor(),\n",
    "    \"Support Vector Machine (Linear Kernel)\": LinearSVR(),\n",
    "    \"   Support Vector Machine (RBF Kernel)\": SVR(),\n",
    "    \"                         Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"                         Random Forest\": RandomForestRegressor(),\n",
    "    \"                     Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"                               XGBoost\": XGBRegressor(),\n",
    "    \"                              LightGBM\": LGBMRegressor(),\n",
    "    \"                              CatBoost\": CatBoostRegressor(verbose=0)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(name + \" trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f9fc4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Linear Regression R^2 Score: 0.85204\n",
      "                   K-Nearest Neighbors R^2 Score: 0.90746\n",
      "                        Neural Network R^2 Score: 0.93407\n",
      "Support Vector Machine (Linear Kernel) R^2 Score: 0.84228\n",
      "   Support Vector Machine (RBF Kernel) R^2 Score: 0.87885\n",
      "                         Decision Tree R^2 Score: 0.93958\n",
      "                         Random Forest R^2 Score: 0.95680\n",
      "                     Gradient Boosting R^2 Score: 0.93109\n",
      "                               XGBoost R^2 Score: 0.97491\n",
      "                              LightGBM R^2 Score: 0.30192\n",
      "                              CatBoost R^2 Score: 0.96683\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items(): \n",
    "    print(name + \" R^2 Score: {:.5f}\".format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e5db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
